{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq(+Prediction).ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Seq2Seq\n",
        "\n",
        "### 한글 --> 영어\n",
        "\n",
        "par_corp.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo1Z7V_hv0p_",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POSCPI_6kTBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "import csv\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx5qiWicXW2_",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "# 파일 불러와서 약간의 전처리\n",
        "files = open(\"./data/par_corp.csv\", encoding='utf-8')\n",
        "\n",
        "re_lines = []\n",
        "for line in files:\n",
        "    if line[0] == '[':\n",
        "        continue\n",
        "    re_line = re.sub('[#\".?!\\n]', '', line)\n",
        "    re_lines.append(re_line)\n",
        "\n",
        "kor = []\n",
        "eng = []\n",
        "count = 0\n",
        "for line in re_lines:\n",
        "    count = count + 1\n",
        "    if count % 2 == 0:\n",
        "        kor.append(line)\n",
        "    else:\n",
        "        eng.append(line)\n",
        "\n",
        "d = {'kor':kor, 'eng':eng}\n",
        "par_corp = pd.DataFrame(d)\n",
        "\n",
        "print(par_corp)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "kor                                        eng\n0            명령은 아래와 같이 반포되었다                  The order went forth that\n1         명령은 반드시 엄격히 준수해야 한다         The orders must be strictly obeyed\n2       운명의 여신은 용사를 특별히 애호하신다                  fortune favors the brave \n3         운명에 그가 죽을 것이라고 정해졌다            Fate destined that he shall die\n4      운명에 그는 목사가 될 것이라고 정해졌다         Fate had ordained him to die young\n...                       ...                                        ...\n47662              사자는 야생동물이다                  The lion is a wild animal\n47663            사자는 황야로 도망갔다  The lion escaped and returned to the wild\n47664   사자는 우리 안에서 천천히 왔다갔다한다       The lion paced the floor of its cage\n47665   젖은 셔츠가 그의 몸에 착 달라붙어있다            The wet shirt clung to his body\n47666      젖은 성냥은 그어도 켜지지 않는다                  Damp matches won't strike\n\n[47667 rows x 2 columns]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcAv930bYjko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 토큰화 (스탑워드 제거) -> 단어 별로 나누기 위해서\n",
        "# 정수 인코딩 -> 컴퓨터가 잘 알아들을수 있도록 단어로 된거를 숫자로 변형\n",
        "# 패딩 -> embedding layer를 통과하려면 벡터의 길이가 같아야하기 때문에\n",
        "encoder_input, decoder_input, decoder_output = [], [], []\n",
        "\n",
        "# 왜 디코더는 인풋/아웃풋 둘 다 존재?\n",
        "# '나는 개와 산책을 하고 있다' -> 인코더를 거치면서 셀/은닉 상태 리턴\n",
        "\n",
        "# 위 문장의 셀 상태랑 은닉 상태 + <start> 가 인풋으로 들어가면\n",
        "\n",
        "# 지금까지 쌓아진 셀/은닉 상태 값, 현재 단어 -> 다음 단어\n",
        "\n",
        "#### <start>가 예측한 단어 = <start> 바로 다음 단어\n",
        "\n",
        "# 훈련을 시키고나서 보면 (상태값이 없다면) <start> 뒤에는 굉장히 다양한 단어가 올 수 있음\n",
        "# <start> 는 뒤에 어떤 단어든지 올 수 있는 단어의 역할\n",
        "# 상태값을 함께 고려하도록 해주면, 모든 단어들 중에서 상태값에 연관되어있는 것만 높을 확률을 부여\n",
        "\n",
        "# 단어의 예측을 바로 전 단어를 기준으로\n",
        "# <end> 는 이제 더 이상 그만 예측하라는 뜻\n",
        "\n",
        "# '<start> i am taking a walk with my dog' -> 추측을 하는데 사용되고 있음\n",
        "# 'i am taking a walk with my dog <end>'\n",
        "\n",
        "for stc in par_corp['kor']:\n",
        "    encoder_input.append(stc.split())\n",
        "\n",
        "# 스타트 뒤에 띄어쓰기 있습니다\n",
        "# <start> 띄어쓰기를 한 이유는 split을 할 때, 띄어쓰기를 기준으로 split하기 때문\n",
        "# 문장이 있으면 ['<start>', 'i', 'am', 'taking']\n",
        "for stc in par_corp['eng']:\n",
        "    decoder_input.append((\"<start> \"+stc).split())\n",
        "\n",
        "# 엔드 앞에 띄어쓰기 있습니다\n",
        "# <end>도 마찬가지\n",
        "for stc in par_corp['eng']:\n",
        "    decoder_output.append((stc+\" <end>\").split())"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfaCZQieZWaN",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "print(encoder_input[:3])\n",
        "print(decoder_input[:3])\n",
        "print(decoder_output[:3])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[['명령은', '아래와', '같이', '반포되었다'], ['명령은', '반드시', '엄격히', '준수해야', '한다'], ['운명의', '여신은', '용사를', '특별히', '애호하신다']]\n[['<start>', 'The', 'order', 'went', 'forth', 'that'], ['<start>', 'The', 'orders', 'must', 'be', 'strictly', 'obeyed'], ['<start>', 'fortune', 'favors', 'the', 'brave']]\n[['The', 'order', 'went', 'forth', 'that', '<end>'], ['The', 'orders', 'must', 'be', 'strictly', 'obeyed', '<end>'], ['fortune', 'favors', 'the', 'brave', '<end>']]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pCmOgCQaDFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_ko = Tokenizer()\n",
        "tokenizer_ko.fit_on_texts(encoder_input)\n",
        "encoder_input = tokenizer_ko.texts_to_sequences(encoder_input)\n",
        "\n",
        "# 1~4999(패딩하기 전) -> 0~4999(패딩하고 난 뒤)\n",
        "tokenizer_en = Tokenizer()\n",
        "tokenizer_en.fit_on_texts(decoder_input)\n",
        "tokenizer_en.fit_on_texts(decoder_output)\n",
        "# 정수 인코딩할 때는 1부터 인덱스를 부여\n",
        "decoder_input = tokenizer_en.texts_to_sequences(decoder_input)\n",
        "decoder_output = tokenizer_en.texts_to_sequences(decoder_output)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYXSFXXw8UCP",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "print(encoder_input[:3])\n",
        "print(decoder_input[:3])\n",
        "print(decoder_output[:3])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[[10325, 1216, 312, 23138], [10325, 66, 8026, 6543, 12], [8027, 23139, 23140, 1162, 23141]]\n[[2, 1, 175, 97, 670, 19], [2, 1, 761, 78, 31, 2133, 11983], [2, 1324, 6699, 1, 2852]]\n[[1, 175, 97, 670, 19, 3], [1, 761, 78, 31, 2133, 11983, 3], [1324, 6699, 1, 2852, 3]]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTq6fFqAagbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "len_ko = []\n",
        "for data in encoder_input:\n",
        "    len_ko.append(len(data))\n",
        "\n",
        "len_en = []\n",
        "for data in decoder_input:\n",
        "    len_en.append(len(data))\n",
        "\n",
        "plt.hist(len_ko, label='ko', alpha=0.7)\n",
        "plt.hist(len_en, label='en', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 388.0125 248.518125\" width=\"388.0125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 388.0125 248.518125 \r\nL 388.0125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 46.0125 224.64 \r\nL 380.8125 224.64 \r\nL 380.8125 7.2 \r\nL 46.0125 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 61.230682 224.64 \r\nL 91.667045 224.64 \r\nL 91.667045 207.145374 \r\nL 61.230682 207.145374 \r\nz\r\n\" style=\"fill:#1f77b4;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 91.667045 224.64 \r\nL 122.103409 224.64 \r\nL 122.103409 17.554286 \r\nL 91.667045 17.554286 \r\nz\r\n\" style=\"fill:#1f77b4;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 122.103409 224.64 \r\nL 152.539773 224.64 \r\nL 152.539773 62.072569 \r\nL 122.103409 62.072569 \r\nz\r\n\" style=\"fill:#1f77b4;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 152.539773 224.64 \r\nL 182.976136 224.64 \r\nL 182.976136 180.715426 \r\nL 152.539773 180.715426 \r\nz\r\n\" style=\"fill:#1f77b4;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_7\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 182.976136 224.64 \r\nL 213.4125 224.64 \r\nL 213.4125 196.983054 \r\nL 182.976136 196.983054 \r\nz\r\n\" style=\"fill:#1f77b4;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_8\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 213.4125 224.64 \r\nL 243.848864 224.64 \r\nL 243.848864 215.180236 \r\nL 213.4125 215.180236 \r\nz\r\n\" style=\"fill:#1f77b4;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_9\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 243.848864 224.64 \r\nL 274.285227 224.64 \r\nL 274.285227 222.453172 \r\nL 243.848864 222.453172 \r\nz\r\n\" style=\"fill:#1f77b4;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_10\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 274.285227 224.64 \r\nL 304.721591 224.64 \r\nL 304.721591 223.650485 \r\nL 274.285227 223.650485 \r\nz\r\n\" style=\"fill:#1f77b4;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_11\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 304.721591 224.64 \r\nL 335.157955 224.64 \r\nL 335.157955 224.392621 \r\nL 304.721591 224.392621 \r\nz\r\n\" style=\"fill:#1f77b4;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_12\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 335.157955 224.64 \r\nL 365.594318 224.64 \r\nL 365.594318 224.580629 \r\nL 335.157955 224.580629 \r\nz\r\n\" style=\"fill:#1f77b4;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_13\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 72.503409 224.64 \r\nL 101.8125 224.64 \r\nL 101.8125 218.811756 \r\nL 72.503409 218.811756 \r\nz\r\n\" style=\"fill:#ff7f0e;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_14\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 101.8125 224.64 \r\nL 131.121591 224.64 \r\nL 131.121591 108.362084 \r\nL 101.8125 108.362084 \r\nz\r\n\" style=\"fill:#ff7f0e;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_15\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 131.121591 224.64 \r\nL 160.430682 224.64 \r\nL 160.430682 85.098585 \r\nL 131.121591 85.098585 \r\nz\r\n\" style=\"fill:#ff7f0e;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_16\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 160.430682 224.64 \r\nL 189.739773 224.64 \r\nL 189.739773 101.682857 \r\nL 160.430682 101.682857 \r\nz\r\n\" style=\"fill:#ff7f0e;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_17\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 189.739773 224.64 \r\nL 219.048864 224.64 \r\nL 219.048864 185.969751 \r\nL 189.739773 185.969751 \r\nz\r\n\" style=\"fill:#ff7f0e;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_18\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 219.048864 224.64 \r\nL 248.357955 224.64 \r\nL 248.357955 196.854417 \r\nL 219.048864 196.854417 \r\nz\r\n\" style=\"fill:#ff7f0e;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_19\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 248.357955 224.64 \r\nL 277.667045 224.64 \r\nL 277.667045 211.637772 \r\nL 248.357955 211.637772 \r\nz\r\n\" style=\"fill:#ff7f0e;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_20\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 277.667045 224.64 \r\nL 306.976136 224.64 \r\nL 306.976136 220.038755 \r\nL 277.667045 220.038755 \r\nz\r\n\" style=\"fill:#ff7f0e;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_21\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 306.976136 224.64 \r\nL 336.285227 224.64 \r\nL 336.285227 221.918834 \r\nL 306.976136 221.918834 \r\nz\r\n\" style=\"fill:#ff7f0e;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"patch_22\">\r\n    <path clip-path=\"url(#p341992d3b4)\" d=\"M 336.285227 224.64 \r\nL 365.594318 224.64 \r\nL 365.594318 224.353041 \r\nL 336.285227 224.353041 \r\nz\r\n\" style=\"fill:#ff7f0e;opacity:0.7;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mc8c8df1294\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"61.230682\" xlink:href=\"#mc8c8df1294\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(58.049432 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"117.594318\" xlink:href=\"#mc8c8df1294\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(114.413068 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"173.957955\" xlink:href=\"#mc8c8df1294\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(167.595455 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.321591\" xlink:href=\"#mc8c8df1294\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(223.959091 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"286.685227\" xlink:href=\"#mc8c8df1294\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(280.322727 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"343.048864\" xlink:href=\"#mc8c8df1294\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(336.686364 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m239d2c2b24\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m239d2c2b24\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(32.65 228.439219)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m239d2c2b24\" y=\"199.902123\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 2500 -->\r\n      <g transform=\"translate(13.5625 203.701342)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m239d2c2b24\" y=\"175.164246\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 5000 -->\r\n      <g transform=\"translate(13.5625 178.963465)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m239d2c2b24\" y=\"150.42637\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 7500 -->\r\n      <defs>\r\n       <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n      </defs>\r\n      <g transform=\"translate(13.5625 154.225588)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m239d2c2b24\" y=\"125.688493\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 10000 -->\r\n      <g transform=\"translate(7.2 129.487712)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m239d2c2b24\" y=\"100.950616\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 12500 -->\r\n      <g transform=\"translate(7.2 104.749835)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m239d2c2b24\" y=\"76.212739\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 15000 -->\r\n      <g transform=\"translate(7.2 80.011958)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m239d2c2b24\" y=\"51.474862\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 17500 -->\r\n      <g transform=\"translate(7.2 55.274081)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m239d2c2b24\" y=\"26.736986\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 20000 -->\r\n      <g transform=\"translate(7.2 30.536204)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_23\">\r\n    <path d=\"M 46.0125 224.64 \r\nL 46.0125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_24\">\r\n    <path d=\"M 380.8125 224.64 \r\nL 380.8125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_25\">\r\n    <path d=\"M 46.0125 224.64 \r\nL 380.8125 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_26\">\r\n    <path d=\"M 46.0125 7.2 \r\nL 380.8125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_27\">\r\n     <path d=\"M 329.321875 44.55625 \r\nL 373.8125 44.55625 \r\nQ 375.8125 44.55625 375.8125 42.55625 \r\nL 375.8125 14.2 \r\nQ 375.8125 12.2 373.8125 12.2 \r\nL 329.321875 12.2 \r\nQ 327.321875 12.2 327.321875 14.2 \r\nL 327.321875 42.55625 \r\nQ 327.321875 44.55625 329.321875 44.55625 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"patch_28\">\r\n     <path d=\"M 331.321875 23.798437 \r\nL 351.321875 23.798437 \r\nL 351.321875 16.798437 \r\nL 331.321875 16.798437 \r\nz\r\n\" style=\"fill:#1f77b4;opacity:0.7;\"/>\r\n    </g>\r\n    <g id=\"text_16\">\r\n     <!-- ko -->\r\n     <defs>\r\n      <path d=\"M 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 31.109375 \r\nL 44.921875 54.6875 \r\nL 56.390625 54.6875 \r\nL 27.390625 29.109375 \r\nL 57.625 0 \r\nL 45.90625 0 \r\nL 18.109375 26.703125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nz\r\n\" id=\"DejaVuSans-107\"/>\r\n      <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n     </defs>\r\n     <g transform=\"translate(359.321875 23.798437)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-107\"/>\r\n      <use x=\"54.285156\" xlink:href=\"#DejaVuSans-111\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"patch_29\">\r\n     <path d=\"M 331.321875 38.476562 \r\nL 351.321875 38.476562 \r\nL 351.321875 31.476562 \r\nL 331.321875 31.476562 \r\nz\r\n\" style=\"fill:#ff7f0e;opacity:0.7;\"/>\r\n    </g>\r\n    <g id=\"text_17\">\r\n     <!-- en -->\r\n     <defs>\r\n      <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n     </defs>\r\n     <g transform=\"translate(359.321875 38.476562)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-110\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p341992d3b4\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"46.0125\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjUW8S0yat0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# maxlen 없어도 알아서 잘 패딩합니다\n",
        "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
        "decoder_output = pad_sequences(decoder_output, padding=\"post\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC-qeT2RbLXn",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "print(encoder_input.shape)\n",
        "print(decoder_input.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(47667, 27)\n(47667, 27)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDsiopSnnNPN",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "print(encoder_input[:3])\n",
        "print(decoder_input[:3])\n",
        "print(decoder_output[:3])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[[10325  1216   312 23138     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0]\n [10325    66  8026  6543    12     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0]\n [ 8027 23139 23140  1162 23141     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0]]\n[[    2     1   175    97   670    19     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0]\n [    2     1   761    78    31  2133 11983     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0]\n [    2  1324  6699     1  2852     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0]]\n[[    1   175    97   670    19     3     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0]\n [    1   761    78    31  2133 11983     3     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0]\n [ 1324  6699     1  2852     3     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0]]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE-wR3CIH7Sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 나중에 prediction 할때 사용하기 위함 (인덱스로 단어 찾기)\n",
        "en_to_index = tokenizer_en.word_index\n",
        "index_to_en = tokenizer_en.index_word"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upeuDKL9bgyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3:1로 나눴습니다\n",
        "test_size = 12000\n",
        "encoder_input_train = encoder_input[:-test_size]\n",
        "decoder_input_train = decoder_input[:-test_size]\n",
        "decoder_output_train = decoder_output[:-test_size]\n",
        "\n",
        "encoder_input_test = encoder_input[-test_size:]\n",
        "decoder_input_test = decoder_input[-test_size:]\n",
        "decoder_output_test = decoder_output[-test_size:]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwpCYLhn2yKH",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW50pD4acuds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JztAY3CTc2Wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코더 모델 - 한글 문장 받아서 LSTM 마지막 시점의 은닉/셀 상태 리턴하도록\n",
        "# 훈련할때는 47667(전체데이터)-12000(테스트)=35667(훈련)\n",
        "# input -> 35667 x 27 (훈련할때는)\n",
        "# input -> 12000 x 27 (테스트할때는)\n",
        "encoder_inputs = Input(shape=(27,)) # 27은 한글 문장의 길이\n",
        "# +1해서 패딩까지\n",
        "encoder_embed = Embedding(len(tokenizer_ko.word_index)+1, 50)(encoder_inputs)\n",
        "# 패딩(0)에 해당하는 임베딩 벡터는 제외\n",
        "encoder_mask = Masking(mask_value=0)(encoder_embed)\n",
        "# return state -> 마지막 은닉, 마지막 은닉, 마지막 셀 총 3개 리턴 (오타 아닙니다)\n",
        "# lstm 셀 자체의 한 시점의 출력은 은닉 상태값 -> softmax 함수를 통과하면서 y값\n",
        "# encoder_outputs는 마지막 은닉 상태 값, h_state도 마지막 은닉 상태 값\n",
        "# encoder_outputs == h_state\n",
        "encoder_outputs, h_state, c_state = LSTM(50, return_state=True)(encoder_mask)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BabZhVsmgtYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 디코더 모델 - 인코더의 상태값(h,c)이랑, 영어 문장을 입력받아서 LSTM의 출력값(은닉 상태), 이걸 받아서 softmax 함수를 통과시키도록\n",
        "decoder_inputs = Input(shape=(27,)) #27은 영어 문장의 길이\n",
        "decoder_embed = Embedding(len(tokenizer_en.word_index)+1, 50)(decoder_inputs)\n",
        "decoder_mask = Masking(mask_value=0)(decoder_embed)\n",
        "# return sequences 쓰면 전체 시점의 은닉 상태 값 (각 단어 인풋 별 은닉 상태 값) 을 리턴\n",
        "# 둘 다 쓰게되면 전체 시점의 은닉 상태, 마지막 은닉 상태, 마지막 셀 상태\n",
        "decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n",
        "# decoder_outputs는 전체 시점의 은닉 상태 값\n",
        "# decoder는 마지막 시점의 은닉/셀 상태 값이 중요하지 않기 때문에 _\n",
        "# 위에서 받은 h_state, c_state 값을 초기 상태값으로\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_mask, initial_state=[h_state, c_state])\n",
        "# 패딩을 한 후에 지금 0~단어갯수 -> 수를 가진 decoder_input/output\n",
        "# [0 1 2 3 4 5 6 7 8 9 10 11 ~~~ 단어갯수] -> 어레이\n",
        "# [0번째 인덱스의 단어가 다음단어일 확률 / 1번째 인덱스의 단어가 다음단어일 확률 / 0.2 / 0.3 ... ~ 단어갯수] (지금 input으로 들어간 단어의 다음 단어일 확률값)\n",
        "decoder_dense = Dense(len(tokenizer_en.word_index)+1, activation='softmax')\n",
        "decoder_softmax_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeHWfbFABv0a",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
        "# sparse는 라벨이 정수 형태로 제공될 때 사용되는 함수 (그냥 categorical은 원핫 벡터로 라벨이 제공될 때)\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "# 레이어 별로 가중치가 학습되는 것임\n",
        "model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_output_train, validation_data = ([encoder_input_test, decoder_input_test], decoder_output_test), batch_size = 128, epochs = 50)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Train on 35667 samples, validate on 12000 samples\nEpoch 1/50\n18048/35667 [==============>...............] - ETA: 8:39 - loss: 4.6768 - acc: 0.6759"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-56-d0c4fd765cec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 레이어 별로 가중치가 학습되는 것임\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mencoder_input_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_input_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_output_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_input_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_output_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
            "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNh4E_KBCvz9",
        "colab_type": "text"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7w1CImWCvkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코더가 출력하는 마지막 시점의 셀/은닉 상태 값 따로 구하고\n",
        "# <start> 라는 인풋을 따로 디코더 모델의 lstm에 집어넣어서\n",
        "# lstm에서 내는 아웃풋 다시 lstm에 계속 집어넣는 형태로\n",
        "# 그러다가 <end>가 보이면 그만"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOutYylpDSyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코더가 출력하는 마지막 시점의 셀/은닉 상태 값 따로 구하고\n",
        "# h_state, c_state는 아웃풋 레이어 (LSTM) 를 명시한 것\n",
        "# encoder_inputs는 encoder_input과 다릅니다\n",
        "# 훈련을 하고 나면 레이어 별로 가중치를 학습, 훈련이 되었으니 학습된 가중치를 가진 레이어를 그대로 \n",
        "encoder_model = Model(encoder_inputs, [h_state, c_state])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbs8XXdjDoZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 디코더 모델을 만들건데, 디코더 모델에 초기값으로 넣을 상태값의 모양을 지정\n",
        "encoder_h_state = Input(shape=(50,))\n",
        "encoder_c_state = Input(shape=(50,))\n",
        "\n",
        "# 우리가 시퀀스를 넣을게 아니라, 단어단어를 넣을거기 때문에\n",
        "# 시점이 여러개가 아니라, 한 시점만 존재\n",
        "# 상태값을 자동으로 넘겨주지 않기 때문에, 직접 넘겨줘야한다\n",
        "# 셀 마다마다 상태의 초기값을 지정 / 나오는 상태값을 저장\n",
        "pd_decoder_outputs, pd_h_state, pd_c_state = decoder_lstm(decoder_mask, initial_state=[encoder_h_state, encoder_c_state])\n",
        "pd_decoder_softmax_outputs = decoder_dense(pd_decoder_outputs)\n",
        "\n",
        "# 모델은 디코더 인풋 (<start>), 인코더의 상태값이 인풋으로 들어간다\n",
        "# lstm 셀 통과하면서 예측, softmax 함수를 통과한 출력값 (각 단어별 다음 단어일 확률값), 디코더의 상태값 두 개를 출력하는 것\n",
        "# softmax 함수를 통과한 출력값 (확률) 을 토대로 다음 단어를 확정\n",
        "# 다시 그 단어를 디코더 인풋으로 + 전 시점의 디코더의 상태값이 인풋으로 들어간다\n",
        "decoder_model = Model([decoder_inputs] + [encoder_h_state, encoder_c_state], [pd_decoder_softmax_outputs] + [pd_h_state, pd_c_state])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlia2cnoHndB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_stc = input()\n",
        "token_stc = input_stc.split()\n",
        "encode_stc = tokenizer_ko.texts_to_sequences([token_stc])\n",
        "pad_stc = pad_sequences(encode_stc, maxlen=27, padding=\"post\")\n",
        "\n",
        "# 인코더의 마지막 시점의 셀/은닉 상태 값\n",
        "states_value = encoder_model.predict(pad_stc)\n",
        "\n",
        "# <start> 를 정수 인코딩해서 numpy array 로\n",
        "predicted_seq = np.zeros((1,1))\n",
        "predicted_seq[0, 0] = en_to_index['<start>']\n",
        "\n",
        "# 각 시점마다 예측된 단어를 저장\n",
        "decoded_stc = []\n",
        "\n",
        "while True:\n",
        "    output_words, h, c = decoder_model.predict([predicted_seq] + states_value)\n",
        "\n",
        "    predicted_word = index_to_en[np.argmax(output_words[0,0])]  \n",
        "\n",
        "    if predicted_word == '<end>':\n",
        "        break\n",
        "\n",
        "    decoded_stc.append(predicted_word)\n",
        "\n",
        "    # 처음에는 <start>, 지금은 예측된 단어가 있으니 이것을 인풋으로 넣어주기 위해서 변수의 값을 업데이트\n",
        "    predicted_seq = np.zeros((1,1))\n",
        "    predicted_seq[0, 0] = np.argmax(output_words[0,0])\n",
        "\n",
        "    # 지금 시점의 상태 값을 다음 시점으로 넘기기 위해서 변수를 업데이트\n",
        "    states_value = [h, c]\n",
        "\n",
        "print(' '.join(decoded_stc))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'<start>'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-40-16026728cb38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# <start> 를 정수 인코딩해서 numpy array 로\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mpredicted_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mpredicted_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0men_to_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'<start>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# 각 시점마다 예측된 단어를 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: '<start>'"
          ]
        }
      ]
    }
  ]
}