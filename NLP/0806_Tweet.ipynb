{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596703741528",
   "display_name": "Python 3.7.7 64-bit ('study': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet dataset\n",
    "\n",
    "https://www.kaggle.com/maxjon/complete-tweet-sentiment-extraction-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Flatten, Concatenate, Input, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       textID   sentiment       author  \\\n0  1956967341       empty   xoshayzers   \n1  1956967666     sadness    wannamama   \n2  1956967696     sadness    coolfunky   \n3  1956967789  enthusiasm  czareaquino   \n4  1956968416     neutral    xkilljoyx   \n\n                                                text  \\\n0   i know  i was listenin to bad habit earlier a...   \n1  Layin n bed with a headache  ughhhh...waitin o...   \n2                Funeral ceremony...gloomy friday...   \n3               wants to hang out with friends SOON!   \n4   We want to trade with someone who has Houston...   \n\n                                            old_text       aux_id  \\\n0  @tiffanylue i know  i was listenin to bad habi...  p1000000000   \n1  Layin n bed with a headache  ughhhh...waitin o...   c811396dc2   \n2                Funeral ceremony...gloomy friday...   9063631ab1   \n3               wants to hang out with friends SOON!   2a815f151d   \n4  @dannycastillo We want to trade with someone w...   82565a56d3   \n\n  new_sentiment                                      selected_text  \n0           NaN                                                NaN  \n1      negative                                           headache  \n2      negative                                             gloomy  \n3      positive               wants to hang out with friends SOON!  \n4       neutral  We want to trade with someone who has Houston ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>sentiment</th>\n      <th>author</th>\n      <th>text</th>\n      <th>old_text</th>\n      <th>aux_id</th>\n      <th>new_sentiment</th>\n      <th>selected_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1956967341</td>\n      <td>empty</td>\n      <td>xoshayzers</td>\n      <td>i know  i was listenin to bad habit earlier a...</td>\n      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n      <td>p1000000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1956967666</td>\n      <td>sadness</td>\n      <td>wannamama</td>\n      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n      <td>c811396dc2</td>\n      <td>negative</td>\n      <td>headache</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1956967696</td>\n      <td>sadness</td>\n      <td>coolfunky</td>\n      <td>Funeral ceremony...gloomy friday...</td>\n      <td>Funeral ceremony...gloomy friday...</td>\n      <td>9063631ab1</td>\n      <td>negative</td>\n      <td>gloomy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1956967789</td>\n      <td>enthusiasm</td>\n      <td>czareaquino</td>\n      <td>wants to hang out with friends SOON!</td>\n      <td>wants to hang out with friends SOON!</td>\n      <td>2a815f151d</td>\n      <td>positive</td>\n      <td>wants to hang out with friends SOON!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1956968416</td>\n      <td>neutral</td>\n      <td>xkilljoyx</td>\n      <td>We want to trade with someone who has Houston...</td>\n      <td>@dannycastillo We want to trade with someone w...</td>\n      <td>82565a56d3</td>\n      <td>neutral</td>\n      <td>We want to trade with someone who has Houston ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "tweet_data = pd.read_csv('./data/tweet_dataset.csv')\n",
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                text   sentiment\n0   i know  i was listenin to bad habit earlier a...       empty\n1  Layin n bed with a headache  ughhhh...waitin o...     sadness\n2                Funeral ceremony...gloomy friday...     sadness\n3               wants to hang out with friends SOON!  enthusiasm\n4   We want to trade with someone who has Houston...     neutral",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i know  i was listenin to bad habit earlier a...</td>\n      <td>empty</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Funeral ceremony...gloomy friday...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>wants to hang out with friends SOON!</td>\n      <td>enthusiasm</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>We want to trade with someone who has Houston...</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "tweet_data = tweet_data.loc[:, ['text', 'sentiment']]\n",
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([0, 1, 1, ..., 6, 9, 6], dtype=int64),\n Index(['empty', 'sadness', 'enthusiasm', 'neutral', 'worry', 'surprise',\n        'love', 'fun', 'hate', 'happiness', 'boredom', 'relief', 'anger'],\n       dtype='object'))"
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "pd.factorize(tweet_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['empty', 'sadness', 'enthusiasm', 'neutral', 'worry', 'surprise',\n       'love', 'fun', 'hate', 'happiness', 'boredom', 'relief', 'anger'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "category_list = pd.factorize(tweet_data['sentiment'])[1]\n",
    "category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                text  sentiment\n0   i know  i was listenin to bad habit earlier a...          0\n1  Layin n bed with a headache  ughhhh...waitin o...          1\n2                Funeral ceremony...gloomy friday...          1\n3               wants to hang out with friends SOON!          2\n4   We want to trade with someone who has Houston...          3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i know  i was listenin to bad habit earlier a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Funeral ceremony...gloomy friday...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>wants to hang out with friends SOON!</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>We want to trade with someone who has Houston...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "tweet_data['sentiment'] = pd.factorize(tweet_data['sentiment'])[0]\n",
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data['text'] = tweet_data['text'].str.replace(\"[^\\w]\", \" \")\n",
    "# tweet_data['text'] = tweet_data['text'].str.replace(\"[^\\(0-9)]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = tweet_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_train, tweet_test, y_train, y_test = train_test_split(tweet_data['text'], tweet_data['sentiment'], random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(13, 13)"
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "len(y_train[0]), len(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stopwords = ['a', 'an']\n",
    "\n",
    "X_train = []\n",
    "for stc in tweet_train:\n",
    "    token = []\n",
    "    # print(stc)\n",
    "    words = stc.split()\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            token.append(word)\n",
    "    X_train.append(token)\n",
    "\n",
    "\n",
    "X_test = []\n",
    "for stc in tweet_test:\n",
    "    token = []\n",
    "    for word in stc.split():\n",
    "        if word not in stopwords:\n",
    "            token.append(word)\n",
    "    X_test.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "27921\n16939\n"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(25000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "print(len(tokenizer.word_index))\n",
    "\n",
    "low_count = 0\n",
    "for word, word_count in tokenizer.word_counts.items():\n",
    "    if word_count == 1:\n",
    "        low_count += 1\n",
    "print(low_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "40\n"
    }
   ],
   "source": [
    "max_length = 0\n",
    "for data in X_train:\n",
    "    if max_length < len(data):\n",
    "        max_length = len(data)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 40\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(27921, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(13, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 29950 samples, validate on 9984 samples\nEpoch 1/3\n29950/29950 [==============================] - 34s 1ms/sample - loss: 2.3625 - acc: 0.2470 - val_loss: 2.2140 - val_acc: 0.2905\nEpoch 2/3\n29950/29950 [==============================] - 32s 1ms/sample - loss: 2.2067 - acc: 0.3243 - val_loss: 2.1950 - val_acc: 0.2139\nEpoch 3/3\n29950/29950 [==============================] - 34s 1ms/sample - loss: 2.0863 - acc: 0.2799 - val_loss: 2.4072 - val_acc: 0.2837\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1c7c5ee9a48>"
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.         0.04797543 0.01669496 0.06538234 0.13466057 0.03877593\n  0.07940554 0.03044652 0.         0.03297355 0.         0.03044399\n  0.        ]]\n"
    }
   ],
   "source": [
    "sentence = \"I can`t sleep\"\n",
    "\n",
    "token_stc = sentence.split()\n",
    "encode_stc = tokenizer.texts_to_sequences([token_stc])\n",
    "pad_stc = pad_sequences(encode_stc)\n",
    "\n",
    "score = model.predict(pad_stc)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "worry 0.13466057\n"
    }
   ],
   "source": [
    "print(category_list[score.argmax()], score[0, score.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}