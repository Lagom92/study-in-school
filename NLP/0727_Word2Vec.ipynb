{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595837065308",
   "display_name": "Python 3.7.7 64-bit ('study': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "\n",
    "## IMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def open_csv():\n",
    "    # csv파일을 연다!\n",
    "    f = open('./data/IMDB_dataset.csv', 'r', encoding='utf-8')\n",
    "    csvreader = csv.reader(f)\n",
    "    \n",
    "    doc_list = []\n",
    "\n",
    "    next(csvreader)\n",
    "    for f in csvreader:\n",
    "        line = re.compile(\"[^\\w]\").sub(' ', f[0].lower())\n",
    "        doc_list.append(line.split())\n",
    "\n",
    "    return doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'oz', 'episode', 'you', 'll', 'be', 'hooked', 'they', 'are', 'right', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me', 'br', 'br', 'the', 'first', 'thing', 'that', 'struck', 'me', 'about', 'oz', 'was', 'its', 'brutality', 'and', 'unflinching', 'scenes', 'of', 'violence', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'go', 'trust', 'me', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'timid', 'this', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', 'sex', 'or', 'violence', 'its', 'is', 'hardcore', 'in', 'the', 'classic', 'use', 'of', 'the', 'word', 'br', 'br', 'it', 'is', 'called', 'oz', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'oswald', 'maximum', 'security', 'state', 'penitentary', 'it', 'focuses', 'mainly', 'on', 'emerald', 'city', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inwards', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', 'em', 'city', 'is', 'home', 'to', 'many', 'aryans', 'muslims', 'gangstas', 'latinos', 'christians', 'italians', 'irish', 'and', 'more', 'so', 'scuffles', 'death', 'stares', 'dodgy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away', 'br', 'br', 'i', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', 'wouldn', 't', 'dare', 'forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', 'forget', 'charm', 'forget', 'romance', 'oz', 'doesn', 't', 'mess', 'around', 'the', 'first', 'episode', 'i', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', 'i', 'couldn', 't', 'say', 'i', 'was', 'ready', 'for', 'it', 'but', 'as', 'i', 'watched', 'more', 'i', 'developed', 'a', 'taste', 'for', 'oz', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', 'not', 'just', 'violence', 'but', 'injustice', 'crooked', 'guards', 'who', 'll', 'be', 'sold', 'out', 'for', 'a', 'nickel', 'inmates', 'who', 'll', 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', 'well', 'mannered', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitches', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', 'watching', 'oz', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewing', 'thats', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side']\n"
    }
   ],
   "source": [
    "doc_list = open_csv()\n",
    "# print(doc_list[0])\n",
    "\n",
    "model = Word2Vec(sentences=doc_list, size=100, window=3, min_count=3, workers=-1, sg=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec 함수 인자에 대한 설명!\n",
    "\n",
    "- sentences : 문장들\n",
    "\n",
    "- size : 임베딩 벡터의 크기\n",
    "\n",
    "- window : 고려할 앞/뒤 단어의 갯수\n",
    "\n",
    "- min_count : 최소 단어 길이\n",
    "\n",
    "- workers : 사용할 프로세서의 수\n",
    "\n",
    "- sg : 0=cbow, 1=**skipgram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('grabbed', 0.39505261182785034), ('dumbrille', 0.38505125045776367), ('cynic', 0.36763641238212585), ('cothk', 0.36432337760925293), ('obligation', 0.3579435348510742), ('prayed', 0.3572878837585449), ('deviate', 0.3572033643722534), ('quicksilver', 0.35572564601898193), ('masters', 0.3493580222129822), ('passing', 0.3471279740333557)]\n"
    }
   ],
   "source": [
    "model_result = model.wv.most_similar(\"man\")\n",
    "\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('imdb_w2v')\n",
    "imdb_model = KeyedVectors.load_word2vec_format(\"imdb_w2v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 영화 리뷰로 w2v 모델 만들기!\n",
    "\n",
    "- stopwords 제외 리스트를 만들어서, 조사는 제외한다.\n",
    "\n",
    "- ratings.txt 파일만 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def open_csv():\n",
    "    f = open('./data/ratings.txt', 'r', encoding='utf-8')\n",
    "\n",
    "    next(f)\n",
    "    naver_doc_list = []\n",
    "    for line in f:\n",
    "        stc_list = line.split('\\t')\n",
    "        naver_doc_list.append(stc_list[1].split())\n",
    "\n",
    "    return naver_doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "naver_doc_list = open_csv()\n",
    "model_naver = Word2Vec(sentences=naver_doc_list, size=50, window=3, min_count=3, workers=-1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['어릴때보고', '지금다시봐도', '재밌어요ㅋㅋ']"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "naver_doc_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('그래픽만', 0.5392969846725464), ('인셉션', 0.5247762799263), ('제이크', 0.5021212697029114), ('가지지', 0.5011077523231506), ('우울함.', 0.49976545572280884), ('못하네...', 0.49665191769599915), ('신기함.', 0.4886792004108429), ('턱쟁이형님의', 0.4859004318714142), ('두렵지', 0.48356252908706665), ('바보연기', 0.4813482463359833)]\n"
    }
   ],
   "source": [
    "model_result = model_naver.wv.most_similar(\"남자\")\n",
    "\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "model_naver.wv.save_word2vec_format('naver_ratings_w2v')\n",
    "\n",
    "# 불러오기\n",
    "naver_model = KeyedVectors.load_word2vec_format(\"naver_ratings_w2v\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 나중에 추가\n",
    "\n",
    "    - Konlpy 사용\n",
    "\n",
    "    - stopword 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}