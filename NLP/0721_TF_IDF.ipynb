{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595320133352",
   "display_name": "Python 3.7.7 64-bit ('study': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "\n",
    "- 단어 별 정수 인덱스 부여, 빈도수를 기록한 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document-Term Matrix\n",
    "\n",
    "- 전체 문서에서 등장한 단어만큼의 열을 가진 벡터에서 문서 별로 등장한 단어에 빈도수만큼의 수를 부여"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF\n",
    "\n",
    "특정 문서에서 특정 단어가 등장한 횟수를 말한다.\n",
    "\n",
    "## DF\n",
    "\n",
    "특정 단어가 등장한 문서의 수를 말한다.\n",
    "\n",
    "## IDF\n",
    "\n",
    "DF의 역수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF\n",
    "\n",
    "$$\n",
    "log(\\frac{n} {1 + df(t)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 로그를 취해서 수가 너무 커지는 것을 방지\n",
    "\n",
    "- 분모에 1을 더해서 df가 0일 때의 경우를 대비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예시 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "날씨  도  보내세요  좋네요  안녕하세요  잘있어요  하루  만나요  다시  감사해요  오늘  좋은  가\n0   0  0     0    0      1     1   0    1   1     1   0   0  0\n1   0  1     1    0      1     0   1    0   0     0   1   1  0\n2   1  1     0    1      3     0   0    0   0     0   1   0  1\n날씨\n도\n보내세요\n좋네요\n안녕하세요\n잘있어요\n하루\n만나요\n다시\n감사해요\n오늘\n좋은\n가\n            idf\n날씨     0.405465\n도      0.000000\n보내세요   0.405465\n좋네요    0.405465\n안녕하세요 -0.287682\n잘있어요   0.405465\n하루     0.405465\n만나요    0.405465\n다시     0.405465\n감사해요   0.405465\n오늘     0.000000\n좋은     0.405465\n가      0.405465\n         날씨    도      보내세요       좋네요     안녕하세요      잘있어요        하루       만나요  \\\n0  0.000000  0.0  0.000000  0.000000 -0.287682  0.405465  0.000000  0.405465   \n1  0.000000  0.0  0.405465  0.000000 -0.287682  0.000000  0.405465  0.000000   \n2  0.405465  0.0  0.000000  0.405465 -0.863046  0.000000  0.000000  0.000000   \n\n         다시      감사해요   오늘        좋은         가  \n0  0.405465  0.405465  0.0  0.000000  0.000000  \n1  0.000000  0.000000  0.0  0.405465  0.000000  \n2  0.000000  0.000000  0.0  0.000000  0.405465  \n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from math import log\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "doc_list = [\n",
    "    '안녕하세요 감사해요 잘있어요 다시 만나요',\n",
    "    '안녕하세요 오늘도 좋은 하루 보내세요',\n",
    "    '안녕하세요 안녕하세요 안녕하세요 오늘도 날씨가 좋네요',\n",
    "]\n",
    "\n",
    "# 문서 전체의 단어들을 토큰화\n",
    "token_list = Okt().morphs(' '.join(doc_list))\n",
    "\n",
    "# 중복 단어를 제거\n",
    "token_list = list(set(token_list))\n",
    "# print(token_list)\n",
    "\n",
    "def tf(term, document):\n",
    "    # document 에서 term 의 등장 횟수를 count\n",
    "    return document.count(term)\n",
    "\n",
    "def idf(term):\n",
    "    # doc_list 에서 term 이 등장한 문서 수를 count\n",
    "    df = 0\n",
    "    for doc in doc_list:\n",
    "        if term in doc:\n",
    "            df += 1\n",
    "    return log(len(doc_list) / (df+1))\n",
    "\n",
    "def tfidf(term, document):\n",
    "    # tf * idf\n",
    "    return tf(term, document)*idf(term)\n",
    "\n",
    "dtm = []\n",
    "\n",
    "for doc in doc_list:\n",
    "    # document term matrix (문서별 단어 등장 횟수) 를 구현해보자, 3 (문서) x 13 (단어) 의 행렬을 리스트로 구성하면 된다\n",
    "    dtm.append(list())\n",
    "    for token in token_list:\n",
    "        dtm[-1].append(tf(token, doc))\n",
    "\n",
    "dtm_pd = pd.DataFrame(dtm, columns=token_list)\n",
    "print(dtm_pd)\n",
    "\n",
    "idf_list = []\n",
    "\n",
    "for token in token_list:\n",
    "    # 단어별로 idf의 값을 구한 리스트를 만들어보자\n",
    "    # 위 idf 함수를 이용하면 된다\n",
    "    print(token)\n",
    "    idf_list.append(idf(token))\n",
    "\n",
    "idf_pd = pd.DataFrame(idf_list, columns=['idf'], index=token_list)\n",
    "print(idf_pd)\n",
    "\n",
    "tfidf_list = []\n",
    "\n",
    "for doc in doc_list:\n",
    "    # tfidf 를 구현해보자, 3 (문서) x 13 (단어) 의 행렬을 리스트로 구성하면 된다\n",
    "    # 내부의 요소는 모두 tfidf 값으로 구성\n",
    "    tfidf_list.append(list())\n",
    "    for token in token_list:\n",
    "        tfidf_list[-1].append(tfidf(token, doc))\n",
    "\n",
    "tfidf_pd = pd.DataFrame(tfidf_list, columns=token_list)\n",
    "print(tfidf_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}